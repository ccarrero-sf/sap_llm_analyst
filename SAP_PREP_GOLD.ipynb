{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ejlf2gagnf5fnbubodz5",
   "authorId": "5744486210470",
   "authorName": "CCARRERO",
   "authorEmail": "carlos.carrero@snowflake.com",
   "sessionId": "ef41e741-2482-4b79-8d32-902f11673fbc",
   "lastEditTime": 1742466449087
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b77b7ac-3e50-462a-927a-61e9f6d656d9",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": "# Snowflake Cortex AI - Transforming & Semantic Model Generation\n\nThis notebook shows how you can use Large Language Models to help you transforming from raw, bronze to gold layer with the goal of generating a semantic model where users can ask questions using natural language. The bronze layer will have tables with column names that meaningful to Analyst. The Gold Layer will have the views that will be used by Cortex Analyst, Snowflake text-2-sql capability. "
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nsession",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c555cbef-c78e-4f99-9061-90518e105534",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "Change this definition in case you want to use other names or LLMs. Note this has been tested using the Anthropic model claude-3-5-sonnet. For LLM Region availability check: https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions or enable Cross-Region Support."
  },
  {
   "cell_type": "code",
   "id": "62f0b949-d8f9-4a3d-a517-f361026eb030",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": "LLM = 'claude-3-5-sonnet'\nRAW_LAYER = 'SAP_RAW'\nBRONZE_LAYER = 'SAP_BRONZE'\nGOLD_LAYER = 'SAP_GOLD'\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b49b2ca9-7e67-4787-9d8d-7698ec1c4028",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "Note this Notebook is expected to run in a test database and it will create a clean environment. This is replacing the BRONZE_LAYER schema in case it exists!!"
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "session.sql(f'create or replace schema {BRONZE_LAYER}').collect()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9b06e606-ec6a-479e-981f-a01d12ceeb79",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "### Asking LLM how to generate new tables in BRONZE layer and copy from RAW\n\nLet's use the power of LLMs to translate column names into something meaningful for analyst and provide the SQL to crate new tables and copy the content from RAW ones. This will take a few minutes"
  },
  {
   "cell_type": "code",
   "id": "901d0dde-3289-471d-9b2b-7d18a42d74c4",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import re\n\ntable_names = [\"0fi_ar_4\", \"0customer_attr\", \"0material_attr\"]\n\nresults = {}\n\nfor table in table_names:\n    \n    sql_text = f\"\"\"\n    select snowflake.cortex.complete('{LLM}', '\n    Generate a new SQL CREATE OR REPLACE table statement which will replace all \n    the below column names by easy and clear to understand column names for a \n    data analyst. Generate the SQL to copy the data from the source table to the\n    target table respecting the column names. \n    The data types should be kept the same. Source schema is called {RAW_LAYER}. \n    Target schema is called {BRONZE_LAYER}. \n    It should in run Snowflake.'  \n    || GET_DDL('table','{RAW_LAYER}.\"{table}\"') );\n    \"\"\"\n\n    full_text_str = session.sql(sql_text).collect()[0][0]\n\n    # Extract content between ```sql and ```\n    match = re.search(r\"```sql(.*?)```\", full_text_str, re.DOTALL)\n    if match:\n        extracted_sql = match.group(1).strip()\n        extracted_sql = extracted_sql.replace('\"', '\\\"')  # Double double-quotes for SQL safety\n\n    else:\n        extracted_sql = '\"\"\" \"\"\"'\n        \n    results[table] = {\n        \"table_name\": table,\n        \"full_output\": full_text_str,\n        \"extracted_sql\": extracted_sql\n    }\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d14c4d6-ca87-44d2-ae92-e69d06ac7f9b",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "Visualize the results before executing. Click on each expander to review:"
  },
  {
   "cell_type": "code",
   "id": "01fb8494-e331-4447-89c8-d8d2fa7ea734",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "for table, data in results.items():\n    with st.expander(f\"Full Output for Table: {data['table_name']}\"):\n        st.subheader(\"Full Output:\")\n        st.code(data[\"full_output\"], language=\"sql\")\n\n    with st.expander(f\"SQL for Table: {data['table_name']}\"):\n        st.subheader(\"Extracted SQL:\")\n        st.code(data[\"extracted_sql\"], language=\"sql\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f9bf96f9-c0cd-45ce-8d2b-667c9ce385d7",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "If you are ok with the output, run next cell to extract the SQL provided to CREATE the new table and the one to INSERT the data:"
  },
  {
   "cell_type": "code",
   "id": "96fdc130-9e24-4624-833c-1ed4c655add0",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "import re\n\ncreate_sql_statements = \"\"\n\nfor table, data in results.items():\n    extracted_sql = data[\"extracted_sql\"]\n\n    # Updated regex to ensure we capture full CREATE and INSERT statements ending in ');'\n    sql_statements = re.split(r';\\s*\\n', extracted_sql.strip())\n    \n    # Extracting the CREATE TABLE and INSERT statements\n    create_table_sql = sql_statements[0] + \";\"\n    insert_sql = sql_statements[1] + \";\"\n    \n    print(f\"CREATING TABLE: {table}\")\n    session.sql(create_table_sql).collect()\n    create_sql_statements += create_table_sql\n    \n    print(f\"INSERT INTO TABLE {table}:\")\n    session.sql(insert_sql).collect()\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b95836f1-e4d8-48bf-82d2-765d4e4f2f3c",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "One of the advantages of Snowflake Notebooks is that you can combine Python, SQL and Markdown! Let's see what tables we got in this layer:"
  },
  {
   "cell_type": "code",
   "id": "b64f9a7e-69f9-4bc9-8636-64c2474e1b56",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": "show tables;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ec3e9e2-e690-4c00-bffd-535ea60f9a64",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "select * from ACCOUNTS_RECEIVABLE limit 5;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fc973f7-62df-4043-ae4a-7bdc042a152a",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "### Generaing GOLD Layer\n\nLet's use the power of LLMs to create a Data MART with the previous tables. This will contain the most important information joining the 3 tables:\n"
  },
  {
   "cell_type": "code",
   "id": "ef6a730b-f5cf-47ce-980d-d9de7405fa29",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "sql_text3 = f\"\"\"\nselect snowflake.cortex.complete('{LLM}', '\nGenerate a Data MART table selecting up to 20 most representative columns and joining they key columns properly.\nCreate the new table under {GOLD_LAYER} schema.\nThese are the tables to be used:\n{create_sql_statements}');\n\"\"\"\n#print (sql_text)\n\nfull_text_str2 = session.sql(sql_text3).collect()[0][0]\n\n# Extract content between ```sql and ```\nmatch = re.search(r\"```sql(.*?)```\", full_text_str2, re.DOTALL)\nif match:\n    extracted_sql2 = match.group(1).strip()\n    extracted_sql2 = extracted_sql2.replace('\"', '\\\"')  # Double double-quotes for SQL safety\n\nelse:\n    extracted_sql2 = '\"\"\" \"\"\"'\n    ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53ae3e52-936e-443c-8664-912ff7a4d46d",
   "metadata": {
    "name": "cell24",
    "collapsed": false
   },
   "source": "Check results:"
  },
  {
   "cell_type": "code",
   "id": "33af60a6-6491-4199-a019-bdc1e111ffa6",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "with st.expander(f\"Full Explanation:\"):\n    st.code(full_text_str2, language=\"sql\")\n\nwith st.expander(f\"SQL to build Mart:\"):\n    st.code(extracted_sql2, language=\"sql\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "201bdb46-5808-4025-a5f8-bcbc0bd00e85",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "Create the GOLD schema and crate the table:"
  },
  {
   "cell_type": "code",
   "id": "19965abd-372b-4703-9842-4b7a2224e318",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "session.sql('create or replace schema SAP_GOLD').collect()\nsession.sql(extracted_sql2).collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3320ef68-c41a-4438-b148-8f0cbd50b16d",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\nselect * from ACCOUNTS_RECEIVABLE_MART limit 50;\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b3755f9-1067-4e91-9220-9bca54e88f69",
   "metadata": {
    "name": "cell29",
    "collapsed": false
   },
   "source": "### Semantic Model: Cortex Search and Cortex Analyst\n\nUsing Snowflake Snowsight UI, we are going to create the Semantic Model that will be used by Cortex Analys to allow business users ask questions in natural language.\n\nAs we have a large number of CUSTOMER_NAME and CUSTOEMR_CITY, and Aanlyst may want to ask for any of them, we are going to use the integration of Cortex Search and Cortex Analyst. \n\nCortex Search will be enabled on those columns, so Cortex Analyst can retrieval names when needed, without having to provide all possible names in the semantic file."
  },
  {
   "cell_type": "code",
   "id": "447fb0c5-6fa0-4af1-9434-8b242d0fcbbd",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE CORTEX SEARCH SERVICE _ANALYST_CUSTOMER_NAME_SEARCH\n  ON CUSTOMER_NAME\n  WAREHOUSE = COMPUTE_WH\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\nAS (\n  SELECT\n      DISTINCT CUSTOMER_NAME\n  FROM ACCOUNTS_RECEIVABLE_MART\n);\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE _ANALYST_CUSTOMER_CITY_SEARCH\n  ON CUSTOMER_CITY\n  WAREHOUSE = COMPUTE_WH\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\nAS (\n  SELECT\n      DISTINCT CUSTOMER_CITY\n  FROM ACCOUNTS_RECEIVABLE_MART\n);\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f6ae749-02c8-4a97-8efb-56f666136b99",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "Let's crate on Stage to keep the Semantic Models that will be crated later using the Cortex Analyst Semantic Model Generator."
  },
  {
   "cell_type": "code",
   "id": "10d8969c-0d77-4521-8eae-8a9fd4dd9e57",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "use schema PUBLIC;\n\nCREATE OR REPLACE STAGE SEMANTIC_MODELS\n  DIRECTORY = (ENABLE = TRUE)\n  ENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );\n\n  ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "778f6d3d-d460-4074-8ffd-689ddb0a473f",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "sql_text = f\"\"\"\nselect snowflake.cortex.complete('{LLM}', '\nProvide 5 examples of questions that can be asked to this data mart:\n{extracted_sql2}');\n\"\"\"\n#print (sql_text)\n\nfull_text_str3 = session.sql(sql_text).collect()[0][0]\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f2373b9-2c69-42b7-8a6f-aacb1062e68a",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "with st.expander(\"Questions:\"):\n    st.code(full_text_str3, language=\"sql\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ae02169-ce9b-47ff-8968-401b90023aff",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}